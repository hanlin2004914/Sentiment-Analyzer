{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZeXyR-qvmJ4r"
      },
      "outputs": [],
      "source": [
        "%pip -q install --upgrade --force-reinstall \\\n",
        "  openai>=1.30.0 datasets>=2.19.0 scikit-learn>=1.4.2 tqdm>=4.66.4 \\\n",
        "  pandas==2.2.2 numpy==2.0.2 \"pyarrow<20\" requests==2.32.4 \"pydantic<2.12\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, getpass\n",
        "from datasets import load_dataset\n",
        "\n",
        "# OpenAI key\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API key: \")\n",
        "\n",
        "DATASET = \"TheFinAI/flare-fiqasa\"\n",
        "\n",
        "# If gated, pass HF_TOKEN\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "\n",
        "try:\n",
        "    ds_all = load_dataset(DATASET, token=HF_TOKEN)\n",
        "except Exception:\n",
        "    try:\n",
        "        from huggingface_hub import notebook_login\n",
        "        notebook_login()\n",
        "        ds_all = load_dataset(DATASET)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Hugging Face access required: {e}\")\n",
        "\n",
        "SPLIT = \"train\" if \"train\" in ds_all else list(ds_all.keys())[0]\n",
        "ds = ds_all[SPLIT]\n",
        "print(f\"Loaded {DATASET} [{SPLIT}]  n={len(ds)}\")\n",
        "print(\"Columns:\", ds.column_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CktNvuP6n1d5",
        "outputId": "2aa46d45-c428-482d-ae92-67e95918f779"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded TheFinAI/flare-fiqasa [train]  n=750\n",
            "Columns: ['id', 'query', 'answer', 'text', 'choices', 'gold']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from collections import OrderedDict\n",
        "import re\n",
        "\n",
        "# Eval config\n",
        "MODEL        = \"o3\"     # change to \"o3-mini\" if you want the mini model\n",
        "MAX_SAMPLES  = None      # set 0/None for full split once things look good\n",
        "QPS_DELAY    = 1.0      # gentle throttle to reduce 429s\n",
        "MAX_RETRIES  = 6\n",
        "\n",
        "def row_text(row):\n",
        "    q = (row.get(\"query\") or \"\").strip()\n",
        "    t = (row.get(\"text\")  or \"\").strip()\n",
        "    return f\"{q}\\n\\nText:\\n{t}\" if (q and t) else (q or t)\n",
        "\n",
        "def normalize_choices(raw):\n",
        "    out = []\n",
        "    if isinstance(raw, list):\n",
        "        for x in raw:\n",
        "            if isinstance(x, str):\n",
        "                s = x.strip()\n",
        "            elif isinstance(x, dict):\n",
        "                s = str(x.get(\"label\") or x.get(\"text\") or x.get(\"value\") or x.get(\"choice\") or \"\").strip()\n",
        "            else:\n",
        "                s = str(x).strip()\n",
        "            if s:\n",
        "                out.append(s)\n",
        "    return out\n",
        "\n",
        "def gold_to_label(row, choices: List[str]):\n",
        "    g = row.get(\"gold\", None)\n",
        "    if g is None:\n",
        "        g = row.get(\"answer\", None)\n",
        "    if isinstance(g, int):\n",
        "        return choices[g] if 0 <= g < len(choices) else str(g)\n",
        "    if isinstance(g, str):\n",
        "        gs = g.strip()\n",
        "        for c in choices:\n",
        "            if gs.lower() == c.lower():\n",
        "                return c\n",
        "        return gs\n",
        "    return str(g)\n"
      ],
      "metadata": {
        "id": "g913P-igoZRH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, re, time, random\n",
        "from typing import List, Tuple\n",
        "from openai import OpenAI, APIStatusError, RateLimitError, APIConnectionError, APIError\n",
        "\n",
        "client = OpenAI()  # uses OPENAI_API_KEY\n",
        "assert globals().get(\"MODEL\", \"o3\") == \"o3\", \"This cell is o3-only. Set MODEL='o3' in Cell 3.\"\n",
        "\n",
        "QPS_DELAY   = globals().get(\"QPS_DELAY\", 1.0)\n",
        "MAX_RETRIES = globals().get(\"MAX_RETRIES\", 6)\n",
        "\n",
        "def call_o3_json(text: str, labels: List[str]) -> Tuple[str, float, dict]:\n",
        "    \"\"\"\n",
        "    Ask o3 to choose ONE label from `labels`.\n",
        "    Returns (label:str, confidence:float, raw_obj_or_text:dict).\n",
        "    Uses Chat Completions with default temperature (required by o3).\n",
        "    \"\"\"\n",
        "    sys = \"Return only valid JSON. Choose exactly one label from the provided set.\"\n",
        "    user = f\"\"\"Choose ONE label from this set:\n",
        "{labels}\n",
        "\n",
        "Return ONLY this JSON (no prose):\n",
        "{{\"label\": \"<one of {labels}>\", \"confidence\": <0..1>}}\n",
        "\n",
        "Text:\n",
        "{text}\"\"\"\n",
        "\n",
        "    def _once():\n",
        "\n",
        "        return client.chat.completions.create(\n",
        "            model=\"o3\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": sys},\n",
        "                {\"role\": \"user\",   \"content\": user},\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    last_err = None\n",
        "    for k in range(MAX_RETRIES):\n",
        "        try:\n",
        "            r = _once()\n",
        "            raw = r.choices[0].message.content.strip()\n",
        "\n",
        "            # Try strict JSON first\n",
        "            try:\n",
        "                obj  = json.loads(raw)\n",
        "                lab  = obj.get(\"label\")\n",
        "                conf = float(obj.get(\"confidence\", 0) or 0.0)\n",
        "            except Exception:\n",
        "                # Salvage by matching any label token\n",
        "                low = raw.lower()\n",
        "                lab = next((L for L in labels if re.search(rf\"\\b{re.escape(L.lower())}\\b\", low)), None)\n",
        "                if lab is None:\n",
        "                    lab = labels[0]\n",
        "                conf = 0.0\n",
        "                obj  = {\"label\": lab, \"raw\": raw}\n",
        "\n",
        "            # Case-insensitive normalization to provided labels\n",
        "            for L in labels:\n",
        "                if str(lab).lower() == L.lower():\n",
        "                    lab = L; break\n",
        "\n",
        "            return lab, conf, obj\n",
        "\n",
        "        except APIStatusError as e:\n",
        "\n",
        "            code = getattr(e, \"status_code\", None)\n",
        "            if code in (400, 401, 403, 404):\n",
        "\n",
        "                raise RuntimeError(\n",
        "                    f\"o3 request failed (HTTP {code}). Details: {e}\"\n",
        "                ) from e\n",
        "            last_err = e\n",
        "            time.sleep((2**k) + random.random())\n",
        "\n",
        "        except (RateLimitError, APIConnectionError, APIError) as e:\n",
        "            last_err = e\n",
        "            time.sleep((2**k) + random.random())\n",
        "\n",
        "    raise last_err or RuntimeError(\"call_o3_json failed\")\n"
      ],
      "metadata": {
        "id": "akZzeaYcoeho"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
        "\n",
        "# Index to evaluate\n",
        "N = (MAX_SAMPLES or len(ds))\n",
        "idx = list(range(N))\n",
        "\n",
        "gold, pred, rows = [], [], []\n",
        "labels_seen = OrderedDict()\n",
        "\n",
        "for i in tqdm(idx, desc=f\"o3 on {SPLIT}\"):\n",
        "    row = ds[i]\n",
        "    choices = normalize_choices(row.get(\"choices\")) or [\"negative\",\"neutral\",\"positive\"]\n",
        "    for c in choices: labels_seen.setdefault(c, None)\n",
        "    g = gold_to_label(row, choices)\n",
        "    labels_seen.setdefault(g, None)\n",
        "\n",
        "    time.sleep(QPS_DELAY)\n",
        "    lab, conf, raw = call_o3_json(row_text(row), choices)\n",
        "\n",
        "    gold.append(g); pred.append(lab)\n",
        "    rows.append({\"text\": row_text(row), \"gold\": g, \"pred\": lab})\n",
        "\n",
        "# Metrics\n",
        "label_list = list(labels_seen.keys())\n",
        "P,R,F1,S = precision_recall_fscore_support(gold, pred, labels=label_list, zero_division=0)\n",
        "acc = accuracy_score(gold, pred)\n",
        "f1_micro = f1_score(gold, pred, average=\"micro\")\n",
        "f1_macro = f1_score(gold, pred, average=\"macro\")\n",
        "report = classification_report(gold, pred, labels=label_list, digits=4, zero_division=0)\n",
        "cm = confusion_matrix(gold, pred, labels=label_list).tolist()\n",
        "\n",
        "print({\"n\":len(gold), \"accuracy\":round(acc,4), \"f1_micro\":round(f1_micro,4), \"f1_macro\":round(f1_macro,4)})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNGJ7xdFoid5",
        "outputId": "089bf165-1937-48e7-c47a-f8008d3945e0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "o3 on train: 100%|██████████| 750/750 [46:55<00:00,  3.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n': 750, 'accuracy': 0.8227, 'f1_micro': 0.8227, 'f1_macro': 0.6931}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}