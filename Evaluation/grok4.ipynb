{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0vXnXEso4dsS"
      },
      "outputs": [],
      "source": [
        "%pip -q install --upgrade --force-reinstall \\\n",
        "  openai>=1.30.0 datasets>=2.19.0 scikit-learn>=1.4.2 tqdm>=4.66.4 huggingface_hub>=0.24.0 \\\n",
        "  pandas==2.2.2 numpy==2.0.2 \"pyarrow<20\" requests==2.32.4 \"pydantic<2.12\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "K6j0mjt75C5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb2ce5b-85ba-4816-d379-e09f124c9ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grok client ready ✅ Model: grok-4\n"
          ]
        }
      ],
      "source": [
        "import os, getpass\n",
        "from openai import OpenAI\n",
        "\n",
        "#  xAI key securely\n",
        "if not os.getenv(\"XAI_API_KEY\"):\n",
        "    os.environ[\"XAI_API_KEY\"] = getpass.getpass(\"xAI API key: \")\n",
        "\n",
        "# xAI uses an OpenAI-compatible API\n",
        "BASE_URL = os.getenv(\"XAI_BASE_URL\", \"https://api.x.ai/v1\")\n",
        "\n",
        "#  Grok model\n",
        "MODEL_NAME = os.getenv(\"GROK_MODEL\", \"grok-4\")\n",
        "\n",
        "client = OpenAI(api_key=os.environ[\"XAI_API_KEY\"], base_url=BASE_URL)\n",
        "print(\"Grok client ready ✅\", \"Model:\", MODEL_NAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dTntP4w75Ik2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b735704-cda1-4201-c884-03bf957bebde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your HF token (hf_...): ··········\n",
            "Who am I: Hanlin0914\n",
            "en-fpb access OK. SHA: 98f0a91c ...\n",
            "Loaded split: test (n=970)\n"
          ]
        }
      ],
      "source": [
        "# Verify token & access, then load the gated dataset\n",
        "import os, getpass\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Get token\n",
        "token = HfFolder.get_token()\n",
        "if not token:\n",
        "    token = os.getenv(\"HF_TOKEN\") or getpass.getpass(\"Paste your HF token (hf_...): \")\n",
        "\n",
        "api = HfApi()\n",
        "print(\"Who am I:\", api.whoami(token=token).get(\"name\"))\n",
        "\n",
        "# Check access\n",
        "info = api.dataset_info(\"TheFinAI/en-fpb\", token=token)\n",
        "print(\"en-fpb access OK. SHA:\", info.sha[:8], \"...\")\n",
        "\n",
        "# Now load the dataset with the token\n",
        "ds_all = load_dataset(\"TheFinAI/en-fpb\", token=token)\n",
        "split = next((s for s in [\"test\",\"validation\",\"valid\",\"train\"] if s in ds_all), list(ds_all.keys())[0])\n",
        "ds = ds_all[split]\n",
        "print(f\"Loaded split: {split} (n={len(ds)})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R4QWYxYk5Sws"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "import json, re\n",
        "\n",
        "def row_text(row):\n",
        "    q = (row.get(\"query\") or \"\").strip()\n",
        "    t = (row.get(\"text\") or \"\").strip()\n",
        "    return f\"{q}\\n\\nText:\\n{t}\" if (q and t) else (q or t)\n",
        "\n",
        "def normalize_choices(raw):\n",
        "    out = []\n",
        "    if isinstance(raw, list):\n",
        "        for x in raw:\n",
        "            if isinstance(x, str):\n",
        "                s = x.strip()\n",
        "            elif isinstance(x, dict):\n",
        "                s = str(x.get(\"label\") or x.get(\"text\") or x.get(\"value\") or x.get(\"choice\") or \"\").strip()\n",
        "            else:\n",
        "                s = str(x).strip()\n",
        "            if s:\n",
        "                out.append(s)\n",
        "    return out\n",
        "\n",
        "def gold_to_label(row, choices: List[str]):\n",
        "    g = row.get(\"gold\", None)\n",
        "    if g is None:\n",
        "        g = row.get(\"answer\", None)\n",
        "    if isinstance(g, int):\n",
        "        return choices[g] if 0 <= g < len(choices) else str(g)\n",
        "    if isinstance(g, str):\n",
        "        gs = g.strip()\n",
        "        for c in choices:\n",
        "            if gs.lower() == c.lower():\n",
        "                return c\n",
        "        return gs\n",
        "    return str(g)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fLgHVmPn5T3L"
      },
      "outputs": [],
      "source": [
        "import time, random\n",
        "from openai import APIError, APIConnectionError, RateLimitError\n",
        "\n",
        "MAX_RETRIES = 6\n",
        "QPS_DELAY   = 1.0  # polite throttle\n",
        "\n",
        "def call_grok_json(text: str, labels: List[str]) -> Tuple[str, float, dict]:\n",
        "    \"\"\"Ask Grok to return: {\"label\":\"<one>\", \"confidence\": float}\"\"\"\n",
        "    sys = \"Return only valid JSON. Choose exactly one label from the provided set.\"\n",
        "    user = f\"\"\"Choose ONE label from this set:\n",
        "{labels}\n",
        "\n",
        "Return ONLY this JSON (no prose):\n",
        "{{\"label\": \"<one of {labels}>\", \"confidence\": <0..1>}}\n",
        "\n",
        "Text:\n",
        "{text}\"\"\"\n",
        "\n",
        "    last = None\n",
        "    for k in range(MAX_RETRIES):\n",
        "        try:\n",
        "            r = client.chat.completions.create(\n",
        "                model=MODEL_NAME,\n",
        "                temperature=0,\n",
        "                messages=[{\"role\":\"system\",\"content\":sys},\n",
        "                          {\"role\":\"user\",\"content\":user}]\n",
        "            )\n",
        "            raw = r.choices[0].message.content.strip()\n",
        "            try:\n",
        "                obj = json.loads(raw)\n",
        "            except Exception:\n",
        "                # salvage common cases by extracting a label token\n",
        "                low = raw.lower()\n",
        "                for L in labels:\n",
        "                    if re.search(rf\"\\b{re.escape(L.lower())}\\b\", low):\n",
        "                        return L, 0.0, {\"label\": L, \"raw\": raw}\n",
        "                # fallback to first label to avoid crashes\n",
        "                return labels[0], 0.0, {\"label\": labels[0], \"raw\": raw}\n",
        "\n",
        "            label = obj.get(\"label\")\n",
        "            conf  = float(obj.get(\"confidence\", 0.0))\n",
        "            if label not in labels:\n",
        "                # try case-insensitive match\n",
        "                for L in labels:\n",
        "                    if str(label).lower() == L.lower():\n",
        "                        label = L; break\n",
        "            if label not in labels:\n",
        "                label = labels[0]\n",
        "            return label, conf, obj\n",
        "\n",
        "        except (RateLimitError, APIConnectionError, APIError) as e:\n",
        "            last = e\n",
        "            time.sleep((2**k) + random.random())\n",
        "    # last-ditch\n",
        "    raise last or RuntimeError(\"Grok call failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "N8puZTJY5W5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9728f3e3-713e-4784-ab07-8f848acc44d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using SPLIT: test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Grok on test: 100%|██████████| 970/970 [2:25:29<00:00,  9.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n': 970, 'acc': 0.7639, 'f1_micro': 0.7639, 'f1_macro': 0.783}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
        "from pathlib import Path\n",
        "\n",
        "MAX_SAMPLES = None\n",
        "\n",
        "idx = list(range(len(ds)))[: (MAX_SAMPLES or len(ds))]\n",
        "gold, pred, rows = [], [], []\n",
        "labels_seen = OrderedDict()\n",
        "\n",
        "# Ensure SPLIT is defined for logging/progress\n",
        "if 'SPLIT' not in globals():\n",
        "    if 'ds_all' in globals() and isinstance(ds_all, dict) and len(ds_all):\n",
        "        SPLIT = next((s for s in [\"test\",\"validation\",\"valid\",\"train\"] if s in ds_all),\n",
        "                     list(ds_all.keys())[0])\n",
        "    else:\n",
        "        SPLIT = \"custom\"\n",
        "print(\"Using SPLIT:\", SPLIT)\n",
        "\n",
        "\n",
        "for i in tqdm(idx, desc=f\"Grok on {SPLIT}\"):\n",
        "    row = ds[i]\n",
        "    choices = normalize_choices(row.get(\"choices\")) or [\"negative\",\"neutral\",\"positive\"]\n",
        "    for c in choices: labels_seen.setdefault(c, None)\n",
        "    g = gold_to_label(row, choices)\n",
        "    labels_seen.setdefault(g, None)\n",
        "\n",
        "    guess, conf, raw = call_grok_json(row_text(row), choices)\n",
        "    gold.append(g); pred.append(guess)\n",
        "    rows.append({\"text\": row_text(row), \"gold\": g, \"pred\": guess})\n",
        "\n",
        "label_list = list(labels_seen.keys())\n",
        "P,R,F1,S = precision_recall_fscore_support(gold, pred, labels=label_list, zero_division=0)\n",
        "acc = accuracy_score(gold, pred)\n",
        "f1_micro = f1_score(gold, pred, average=\"micro\")\n",
        "f1_macro = f1_score(gold, pred, average=\"macro\")\n",
        "report = classification_report(gold, pred, labels=label_list, digits=4, zero_division=0)\n",
        "cm = confusion_matrix(gold, pred, labels=label_list).tolist()\n",
        "\n",
        "print({\"n\":len(gold), \"acc\":round(acc,4), \"f1_micro\":round(f1_micro,4), \"f1_macro\":round(f1_macro,4)})\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}