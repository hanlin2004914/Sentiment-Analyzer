{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ATSUQzivLIRg"
      },
      "outputs": [],
      "source": [
        "%pip -q install --upgrade --force-reinstall \\\n",
        "  openai>=1.30.0 datasets>=2.19.0 scikit-learn>=1.4.2 tqdm>=4.66.4 \\\n",
        "  pandas==2.2.2 numpy==2.0.2 \"pyarrow<20\" requests==2.32.4 \"pydantic<2.12\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "from openai import OpenAI\n",
        "\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API key: \")\n",
        "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not set.\"\n",
        "\n",
        "client = OpenAI()\n",
        "print(\"OpenAI client ready ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIOq3EPqL6FE",
        "outputId": "c39b098b-114a-4079-a1e6-f2cd8b1e7eb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI client ready ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "\n",
        "DATASET = \"TheFinAI/en-fpb\"\n",
        "\n",
        "# Get a HF token\n",
        "token = HfFolder.get_token() or os.getenv(\"HF_TOKEN\")\n",
        "if not token:\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        token = userdata.get(\"HF_TOKEN\")\n",
        "    except Exception:\n",
        "        pass\n",
        "if not token:\n",
        "    token = getpass.getpass(\"Hugging Face token (hf_...): \")\n",
        "\n",
        "# Verify access & persist token\n",
        "api = HfApi()\n",
        "_ = api.dataset_info(DATASET, token=token)\n",
        "HfFolder.save_token(token)\n",
        "print(\"HF access OK ✅\")\n",
        "\n",
        "# Load split\n",
        "ds_all = load_dataset(DATASET, token=token)\n",
        "PREFERRED = [\"test\", \"validation\", \"valid\", \"dev\", \"train\"]\n",
        "SPLIT = next((s for s in PREFERRED if s in ds_all), list(ds_all.keys())[0])\n",
        "ds = ds_all[SPLIT]\n",
        "print(f\"Loaded {DATASET} [{SPLIT}]  n={len(ds)}\")\n",
        "print(\"Columns:\", ds.column_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP10VCiGL_fK",
        "outputId": "543b28b4-bba3-42a3-fea5-6c47ae1a3515"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF access OK ✅\n",
            "Loaded TheFinAI/en-fpb [test]  n=970\n",
            "Columns: ['id', 'query', 'answer', 'text', 'choices', 'gold']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from collections import OrderedDict\n",
        "import re\n",
        "\n",
        "# Eval config\n",
        "MODEL        = \"o3-mini\"\n",
        "MAX_SAMPLES  = 250\n",
        "QPS_DELAY    = 1.0\n",
        "MAX_RETRIES  = 6\n",
        "\n",
        "def row_text(row):\n",
        "    q = (row.get(\"query\") or \"\").strip()\n",
        "    t = (row.get(\"text\")  or \"\").strip()\n",
        "    return f\"{q}\\n\\nText:\\n{t}\" if (q and t) else (q or t)\n",
        "\n",
        "def normalize_choices(raw):\n",
        "    out = []\n",
        "    if isinstance(raw, list):\n",
        "        for x in raw:\n",
        "            if isinstance(x, str):\n",
        "                s = x.strip()\n",
        "            elif isinstance(x, dict):\n",
        "                s = str(x.get(\"label\") or x.get(\"text\") or x.get(\"value\") or x.get(\"choice\") or \"\").strip()\n",
        "            else:\n",
        "                s = str(x).strip()\n",
        "            if s:\n",
        "                out.append(s)\n",
        "    return out\n",
        "\n",
        "def gold_to_label(row, choices: List[str]):\n",
        "    g = row.get(\"gold\", None)\n",
        "    if g is None:\n",
        "        g = row.get(\"answer\", None)\n",
        "    if isinstance(g, int):\n",
        "        return choices[g] if 0 <= g < len(choices) else str(g)\n",
        "    if isinstance(g, str):\n",
        "        gs = g.strip()\n",
        "        for c in choices:\n",
        "            if gs.lower() == c.lower():\n",
        "                return c\n",
        "        return gs\n",
        "    return str(g)\n"
      ],
      "metadata": {
        "id": "g-LcgvqiMKco"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, time, random\n",
        "from typing import Tuple\n",
        "from openai import APIStatusError, RateLimitError, APIConnectionError, APIError\n",
        "\n",
        "def call_o3mini_json(text: str, labels: List[str]) -> Tuple[str, float, dict]:\n",
        "    \"\"\"\n",
        "    Ask o3-mini to choose ONE label from labels.\n",
        "    Returns (label, confidence, raw_json_or_text).\n",
        "    \"\"\"\n",
        "    sys = \"Return only valid JSON. Choose exactly one label from the provided set.\"\n",
        "    user = f\"\"\"Choose ONE label from this set:\n",
        "{labels}\n",
        "\n",
        "Return ONLY this JSON (no prose):\n",
        "{{\"label\": \"<one of {labels}>\", \"confidence\": <0..1>}}\n",
        "\n",
        "Text:\n",
        "{text}\"\"\"\n",
        "\n",
        "    def _once(with_temp: bool):\n",
        "        kwargs = dict(\n",
        "            model=\"o3-mini\",\n",
        "            messages=[\n",
        "                {\"role\":\"system\",\"content\":sys},\n",
        "                {\"role\":\"user\",\"content\":user},\n",
        "            ],\n",
        "        )\n",
        "        if with_temp:\n",
        "            kwargs[\"temperature\"] = 0\n",
        "        return client.chat.completions.create(**kwargs)\n",
        "\n",
        "    last_err = None\n",
        "    for k in range(MAX_RETRIES):\n",
        "        try:\n",
        "            # Try deterministic; if 400 , retry without temperature\n",
        "            try:\n",
        "                r = _once(with_temp=True)\n",
        "            except APIStatusError as e:\n",
        "                if getattr(e, \"status_code\", None) == 400:\n",
        "                    r = _once(with_temp=False)\n",
        "                else:\n",
        "                    raise\n",
        "\n",
        "            raw = r.choices[0].message.content.strip()\n",
        "\n",
        "            # Parse strict JSON first\n",
        "            try:\n",
        "                obj  = json.loads(raw)\n",
        "                lab  = obj.get(\"label\")\n",
        "                conf = float(obj.get(\"confidence\", 0) or 0.0)\n",
        "            except Exception:\n",
        "                # Salvage by matching any label token\n",
        "                low = raw.lower()\n",
        "                lab = next((L for L in labels if re.search(rf\"\\b{re.escape(L.lower())}\\b\", low)), None)\n",
        "                if lab is None:\n",
        "                    lab = labels[0]\n",
        "                conf = 0.0\n",
        "                obj  = {\"label\": lab, \"raw\": raw}\n",
        "\n",
        "            # Normalize case to provided labels\n",
        "            for L in labels:\n",
        "                if str(lab).lower() == L.lower():\n",
        "                    lab = L; break\n",
        "\n",
        "            return lab, conf, obj\n",
        "\n",
        "        except (APIStatusError, RateLimitError, APIConnectionError, APIError) as e:\n",
        "            last_err = e\n",
        "            time.sleep((2**k) + random.random())\n",
        "\n",
        "    raise last_err or RuntimeError(\"call_o3mini_json failed\")\n"
      ],
      "metadata": {
        "id": "VB7BaUWqMPTn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
        "\n",
        "N = (MAX_SAMPLES or len(ds))\n",
        "idx = list(range(N))\n",
        "\n",
        "gold, pred, rows = [], [], []\n",
        "labels_seen = OrderedDict()\n",
        "\n",
        "for i in tqdm(idx, desc=f\"o3-mini on {SPLIT}\"):\n",
        "    row = ds[i]\n",
        "    choices = normalize_choices(row.get(\"choices\")) or [\"negative\",\"neutral\",\"positive\"]\n",
        "    for c in choices: labels_seen.setdefault(c, None)\n",
        "    g = gold_to_label(row, choices)\n",
        "    labels_seen.setdefault(g, None)\n",
        "\n",
        "    time.sleep(QPS_DELAY)\n",
        "    lab, conf, raw = call_o3mini_json(row_text(row), choices)\n",
        "\n",
        "    gold.append(g); pred.append(lab)\n",
        "    rows.append({\"text\": row_text(row), \"gold\": g, \"pred\": lab})\n",
        "\n",
        "# Metrics\n",
        "label_list = list(labels_seen.keys())\n",
        "P,R,F1,S = precision_recall_fscore_support(gold, pred, labels=label_list, zero_division=0)\n",
        "acc = accuracy_score(gold, pred)\n",
        "f1_micro = f1_score(gold, pred, average=\"micro\")\n",
        "f1_macro = f1_score(gold, pred, average=\"macro\")\n",
        "report = classification_report(gold, pred, labels=label_list, digits=4, zero_division=0)\n",
        "cm = confusion_matrix(gold, pred, labels=label_list).tolist()\n",
        "\n",
        "print({\"n\":len(gold), \"accuracy\":round(acc,4), \"f1_micro\":round(f1_micro,4), \"f1_macro\":round(f1_macro,4)})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2DihhVUMUuY",
        "outputId": "0a1c4572-7a55-4eba-985b-28b7a99ad8db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "o3-mini on test: 100%|██████████| 250/250 [17:03<00:00,  4.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n': 250, 'accuracy': 0.676, 'f1_micro': 0.676, 'f1_macro': 0.2689}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}