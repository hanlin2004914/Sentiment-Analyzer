{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q \"openai>=1.40.0\" \"httpx>=0.27.2\" \"httpcore>=1.0.5\" \"pandas>=2.2.2\" \"tqdm>=4.66.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd449de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass, json, time, platform\n",
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "def ver(pkg):\n",
    "    try:\n",
    "        return version(pkg)\n",
    "    except PackageNotFoundError:\n",
    "        return None\n",
    "\n",
    "# ==== Configure DeepSeek ====\n",
    "MODEL    = os.getenv(\"DEEPSEEK_MODEL\", \"Deepseek-VL-7B-Chat\")\n",
    "BASE_URL = os.getenv(\"DEEPSEEK_BASE_URL\", \"https://api.deepseek.com\")\n",
    "\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\") or os.getenv(\"API_KEY\")\n",
    "if not api_key:\n",
    "    api_key = getpass.getpass(\"Paste your DeepSeek API key: \")\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = api_key\n",
    "\n",
    "save_dir  = \"./results_DeepseekVL7BChat\"\n",
    "meta_path = os.path.join(save_dir, \"meta.json\")\n",
    "\n",
    "meta = {\n",
    "    \"model\": MODEL,\n",
    "    \"base_url\": BASE_URL,\n",
    "    \"python\": platform.python_version(),\n",
    "    \"time_utc\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()),\n",
    "    \"openai_pkg\": ver(\"openai\"),\n",
    "    \"httpx\": ver(\"httpx\"),\n",
    "}\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Meta saved ->\", meta_path)\n",
    "print(\"MODEL:\", MODEL, \"| BASE_URL:\", BASE_URL)\n",
    "print(\"DEEPSEEK_API_KEY set:\", bool(os.environ.get(\"DEEPSEEK_API_KEY\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a98b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ[\"DEEPSEEK_API_KEY\"], base_url=BASE_URL)\n",
    "print(\"Client ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0222d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision-language sanity check\n",
    "# You can provide either:\n",
    "# 1) a local image filepath via IMAGE_PATH (it will be base64-encoded), or\n",
    "# 2) an image URL via IMAGE_URL (publicly accessible).\n",
    "import os, base64\n",
    "\n",
    "image_url = os.getenv(\"IMAGE_URL\")\n",
    "image_path = os.getenv(\"IMAGE_PATH\")\n",
    "\n",
    "content_parts = [{\"type\": \"text\", \"text\": \"Describe what's in this image in one sentence.\"}]\n",
    "\n",
    "if image_path and os.path.exists(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    content_parts.append({\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/png;base64,{b64}\"}\n",
    "    })\n",
    "elif image_url:\n",
    "    content_parts.append({\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": image_url}\n",
    "    })\n",
    "else:\n",
    "    print(\"No image provided via IMAGE_PATH or IMAGE_URL; running a text-only prompt instead.\")\n",
    "\n",
    "msgs = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful multimodal assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": content_parts},\n",
    "]\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=msgs,\n",
    "    temperature=0.2,\n",
    "    max_tokens=200,\n",
    ")\n",
    "print(resp.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
