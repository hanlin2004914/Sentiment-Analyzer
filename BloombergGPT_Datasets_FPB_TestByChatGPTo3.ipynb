{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"openai>=2.6.1\" \"httpx==0.28.1\" \"httpcore==1.0.5\" datasets pandas scikit-learn tqdm\n",
        "\n",
        "import os, getpass, re, time\n",
        "from datasets import load_dataset\n",
        "from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Paste your OpenAI API key: \")\n",
        "MODEL = \"o3\"\n",
        "print(\"Model:\", MODEL)\n",
        "\n",
        "ds = load_dataset(\"ChanceFocus/en-fpb\", split=\"test\")\n",
        "print(len(ds), ds.column_names[:8])\n",
        "\n",
        "import openai, httpx\n",
        "print(\"openai:\", openai.__version__)\n",
        "print(\"httpx:\", httpx.__version__)\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "def normalize_to_choice(raw, choices):\n",
        "    if not raw:\n",
        "        return None\n",
        "    s = re.split(r\"[\\r\\n]\", str(raw).strip())[0].strip().strip(\".:;\").lower()\n",
        "    alias = {\"pos\":\"positive\",\"neg\":\"negative\",\"neu\":\"neutral\",\"bullish\":\"positive\",\"bearish\":\"negative\"}\n",
        "    s = alias.get(s, s)\n",
        "    for c in choices:\n",
        "        if s == c.lower():\n",
        "            return c\n",
        "    for c in choices:\n",
        "        if c.lower().startswith(s):\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "SYSTEM = \"You are a financial sentiment classifier. Choose exactly one label from the options. Output ONLY the label.\"\n",
        "\n",
        "def ask_model(sentence, choices, retries=3, sleep=1):\n",
        "    user = f\"Sentence: {sentence}\\nOptions: {', '.join(choices)}\\nAnswer with ONE of the options only.\"\n",
        "    last_e = None\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            resp = client.responses.create(\n",
        "                model=MODEL,\n",
        "                input=user,\n",
        "                instructions=SYSTEM,\n",
        "                max_output_tokens=32\n",
        "            )\n",
        "            return resp.output_text\n",
        "        except Exception as e:\n",
        "            last_e = e\n",
        "            time.sleep(sleep)\n",
        "    raise last_e\n",
        "\n",
        "ex = ds[0]\n",
        "pred_raw = ask_model(ex[\"text\"], list(ex[\"choices\"]))\n",
        "pred = normalize_to_choice(pred_raw, list(ex[\"choices\"]))\n",
        "print(ex[\"text\"], ex[\"choices\"], pred_raw, pred, ex[\"answer\"])\n",
        "\n",
        "N = len(ds)\n",
        "rows, y_true, y_pred = [], [], []\n",
        "for i in tqdm(range(N)):\n",
        "    x = ds[i]\n",
        "    choices = list(x[\"choices\"])\n",
        "    gold = x[\"answer\"]\n",
        "    raw = ask_model(x[\"text\"], choices)\n",
        "    pred = normalize_to_choice(raw, choices) or \"UNKNOWN\"\n",
        "    rows.append({\"id\": x.get(\"id\", i), \"text\": x[\"text\"], \"choices\": \"|\".join(choices), \"pred_raw\": raw, \"pred\": pred, \"label\": gold})\n",
        "    y_true.append(gold)\n",
        "    y_pred.append(pred)\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"/content/fpb_predictions.csv\", index=False)\n",
        "print(\"Saved to /content/fpb_predictions.csv\")\n",
        "\n",
        "ok = df[df[\"pred\"]!=\"UNKNOWN\"]\n",
        "print(\"Used for scoring:\", len(ok), \"/\", len(df))\n",
        "print(\"Accuracy:\", round(accuracy_score(ok[\"label\"], ok[\"pred\"]), 4))\n",
        "print(\"Macro-F1:\", round(f1_score(ok[\"label\"], ok[\"pred\"], average=\"macro\"), 4))\n",
        "print(\"\\nReport:\\n\", classification_report(ok[\"label\"], ok[\"pred\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i15zQBIVKgG",
        "outputId": "7e5d1478-8de0-4c2b-f71d-f4590821666b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPaste your OpenAI API key: ··········\n",
            "Model: o3\n",
            "970 ['id', 'query', 'answer', 'text', 'choices', 'gold']\n",
            "openai: 2.6.1\n",
            "httpx: 0.28.1\n",
            "The new agreement , which expands a long-established cooperation between the companies , involves the transfer of certain engineering and documentation functions from Larox to Etteplan . ['positive', 'neutral', 'negative']  None positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 970/970 [27:39<00:00,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/fpb_predictions.csv\n",
            "Used for scoring: 26 / 970\n",
            "Accuracy: 1.0\n",
            "Macro-F1: 1.0\n",
            "\n",
            "Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00        12\n",
            "     neutral       1.00      1.00      1.00         9\n",
            "    positive       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        26\n",
            "   macro avg       1.00      1.00      1.00        26\n",
            "weighted avg       1.00      1.00      1.00        26\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mSatBNzdohw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}