{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be0dec2-159b-46bf-8a62-165b020b699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste your Hugging Face token:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face token set successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install dependencies & set Hugging Face token\n",
    "%pip install -q \"datasets>=2.19.0\" \"huggingface_hub>=0.24\"\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# 直接设置Hugging Face token，跳过登录界面\n",
    "hf_token = getpass.getpass(\"Paste your Hugging Face token: \")\n",
    "os.environ['HF_TOKEN'] = hf_token\n",
    "os.environ['HUGGINGFACE_HUB_TOKEN'] = hf_token\n",
    "\n",
    "print(\"Hugging Face token set successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f843676-9c49-4ad9-85d4-9c6251b153ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded flare-fpb test: 970 columns: ['id', 'query', 'answer', 'text', 'choices', 'gold']\n",
      "Samples with unusable label: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load FLARE-FPB test set and normalize labels\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "LABELS = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "ds_raw = load_dataset(\"TheFinAI/flare-fpb\", split=\"test\")\n",
    "print(\"Loaded flare-fpb test:\", len(ds_raw), \"columns:\", ds_raw.column_names)\n",
    "\n",
    "_alias = {\"pos\": \"positive\", \"neg\": \"negative\", \"neu\": \"neutral\",\n",
    "          \"bullish\": \"positive\", \"bearish\": \"negative\"}\n",
    "\n",
    "def _norm_label(v):\n",
    "    if v is None: \n",
    "        return None\n",
    "    if isinstance(v, (int, float)) or (isinstance(v, str) and v.isdigit()):\n",
    "        i = int(v)\n",
    "        return LABELS[i] if 0 <= i < len(LABELS) else None\n",
    "    s = str(v).strip().lower()\n",
    "    s = _alias.get(s, s)\n",
    "    return s if s in LABELS else None\n",
    "\n",
    "def _map_row(x):\n",
    "    text = x.get(\"text\") or x.get(\"sentence\") or x.get(\"content\") or x.get(\"input\") or \"\"\n",
    "    lab = _norm_label(x.get(\"label\", x.get(\"labels\", x.get(\"answer\"))))\n",
    "    return {\"text\": text, \"choices\": LABELS, \"answer\": lab}\n",
    "\n",
    "ds = Dataset.from_list([{**r, **_map_row(r)} for r in ds_raw])\n",
    "bad = [i for i, r in enumerate(ds) if r[\"answer\"] not in LABELS]\n",
    "print(\"Samples with unusable label:\", len(bad))\n",
    "assert len(bad) == 0, \"Found unparseable labels; please check the field mapping.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06259457-7882-4801-8a4e-25857693531c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste your DeepSeek API key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta saved -> /content/flare_fpb_deepseek_chat_metadata.json\n",
      "MODEL: deepseek-chat | BASE_URL: https://api.deepseek.com/v1\n",
      "DEEPSEEK_API_KEY is set: True\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Install dependencies, configure DeepSeek, and record experiment metadata\n",
    "%pip install -q \"openai==1.40.2\" \"httpx==0.27.2\" \"httpcore==1.0.5\" \\\n",
    "               \"pandas>=2.2.2\" \"tqdm>=4.66.4\" \"requests>=2.31.0\"\n",
    "\n",
    "import os, getpass, json, time, platform\n",
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "# DeepSeek适配：使用deepseek-chat模型\n",
    "MODEL = \"deepseek-chat\"\n",
    "BASE_URL = \"https://api.deepseek.com/v1\"\n",
    "\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\") or os.getenv(\"API_KEY\")\n",
    "if not api_key:\n",
    "    api_key = getpass.getpass(\"Paste your DeepSeek API key: \")\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = api_key\n",
    "\n",
    "# DeepSeek适配：调整文件命名以区分模型\n",
    "run_tag = f\"flare_fpb_{MODEL.replace('-', '_')}\"\n",
    "save_dir = \"/content\"\n",
    "pred_path = f\"{save_dir}/{run_tag}_predictions.csv\"\n",
    "meta_path = f\"{save_dir}/{run_tag}_metadata.json\"\n",
    "\n",
    "def ver(pkg: str) -> str:\n",
    "    try:\n",
    "        return version(pkg)\n",
    "    except PackageNotFoundError:\n",
    "        return \"not-installed\"\n",
    "\n",
    "# DeepSeek适配：在元数据中标注模型版本信息\n",
    "meta = {\n",
    "    \"dataset\": \"TheFinAI/flare-fpb\",\n",
    "    \"split\": \"test\",\n",
    "    \"labels\": list(LABELS),\n",
    "    \"model\": MODEL,\n",
    "    \"model_variant\": \"standard\",\n",
    "    \"openai_sdk\": ver(\"openai\"),\n",
    "    \"httpx\": ver(\"httpx\"),\n",
    "    \"httpcore\": ver(\"httpcore\"),\n",
    "    \"datasets_version\": ver(\"datasets\"),\n",
    "    \"pandas\": ver(\"pandas\"),\n",
    "    \"tqdm\": ver(\"tqdm\"),\n",
    "    \"time_utc\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()),\n",
    "    \"python\": platform.python_version(),\n",
    "    \"base_url\": BASE_URL,\n",
    "    \"note\": \"DeepSeek-chat model evaluation\"\n",
    "}\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Meta saved ->\", meta_path)\n",
    "print(\"MODEL:\", MODEL, \"| BASE_URL:\", BASE_URL)\n",
    "print(\"DEEPSEEK_API_KEY is set:\", bool(os.environ.get(\"DEEPSEEK_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10d39be-9fd8-4061-894d-0e009009a659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DeepSeek model evaluation on 970 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                              | 30/970 [01:11<36:04,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 30/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████                                                                            | 60/970 [02:21<36:05,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 60/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▌                                                                         | 90/970 [03:34<35:22,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 90/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▉                                                                      | 120/970 [04:44<31:14,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 120/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▎                                                                   | 150/970 [05:58<33:44,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 150/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▊                                                                 | 180/970 [07:11<31:13,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 180/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▎                                                              | 210/970 [08:23<29:57,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 210/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▊                                                            | 240/970 [09:33<29:26,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 240/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▎                                                         | 270/970 [10:43<25:53,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 270/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▋                                                       | 300/970 [11:53<26:41,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 300/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▏                                                    | 330/970 [13:07<26:46,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 330/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████▋                                                  | 360/970 [14:19<25:03,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 360/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▏                                               | 390/970 [15:34<24:08,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 390/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▋                                             | 420/970 [16:43<21:19,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 420/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████                                           | 450/970 [17:56<21:31,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 450/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████▌                                        | 480/970 [19:10<20:06,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 480/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████                                      | 510/970 [20:23<20:21,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 510/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▌                                   | 540/970 [21:35<16:33,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 540/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████                                 | 570/970 [22:47<16:37,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 570/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████▍                              | 600/970 [23:59<15:42,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 600/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████████████████████████████▉                            | 630/970 [25:13<14:05,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 630/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████▍                         | 660/970 [26:26<12:24,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 660/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████████████▉                       | 690/970 [27:42<11:51,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 690/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████▍                    | 720/970 [28:54<10:02,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 720/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████████▊                  | 750/970 [30:10<09:56,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 750/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████▎               | 780/970 [31:24<07:28,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 780/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████████▊             | 810/970 [32:39<06:52,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 810/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████▎          | 840/970 [33:50<04:51,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 840/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████▊        | 870/970 [35:03<04:04,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 870/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▏     | 900/970 [36:14<02:37,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 900/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████████▋   | 930/970 [37:28<01:32,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 930/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████▏| 960/970 [38:41<00:24,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[checkpoint] saved 960/970 -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 970/970 [39:07<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] DeepSeek evaluation completed -> /content/flare_fpb_deepseek_chat_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Inference & evaluation loop (DeepSeek adaptation)\n",
    "import requests, json, os, re, time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "def _strip_code_fences(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    if s.startswith(\"```\"):\n",
    "        s = re.sub(r\"^```[a-zA-Z0-9_-]*\\s*\", \"\", s)\n",
    "        s = re.sub(r\"\\s*```$\", \"\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def _make_user_text(sentence: str, choices=(\"\",)):\n",
    "    # DeepSeek适配：保持原有提示词结构\n",
    "    return (\n",
    "        \"Task: classify the sentence into exactly one of these labels: \"\n",
    "        f\"{', '.join(choices)}.\\n\\n\"\n",
    "        f\"Sentence: {sentence}\\n\\n\"\n",
    "        \"Return ONLY a JSON object on a single line, exactly in this form:\\n\"\n",
    "        \"{\\\"label\\\":\\\"negative|neutral|positive\\\"}\\n\"\n",
    "        \"No code fences, no extra text, no explanation.\"\n",
    "    )\n",
    "\n",
    "def ask_deepseek_once(sentence, choices=(\"negative\", \"neutral\", \"positive\")):\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ['DEEPSEEK_API_KEY'],\n",
    "        base_url=BASE_URL\n",
    "    )\n",
    "    \n",
    "    user_text = _make_user_text(sentence, choices)\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_text}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content.strip()\n",
    "        content = _strip_code_fences(content)\n",
    "        \n",
    "        # 尝试解析JSON\n",
    "        obj = json.loads(content)\n",
    "        lab = obj.get(\"label\")\n",
    "        if lab not in choices:\n",
    "            raise RuntimeError(f\"Invalid label {lab!r}; raw json: {obj}\")\n",
    "        return lab\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        # 如果JSON解析失败，尝试从文本中提取标签\n",
    "        content_lower = content.lower()\n",
    "        for choice in choices:\n",
    "            if choice in content_lower:\n",
    "                return choice\n",
    "        raise RuntimeError(f\"Could not parse label from response: {content}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"API call failed: {str(e)}\")\n",
    "\n",
    "def ask_deepseek(sentence, choices=(\"negative\", \"neutral\", \"positive\")):\n",
    "    # DeepSeek适配：调整重试策略\n",
    "    delay = 2.0\n",
    "    for attempt in range(5):  # 减少重试次数\n",
    "        try:\n",
    "            return ask_deepseek_once(sentence, choices)\n",
    "        except RuntimeError as e:\n",
    "            msg = str(e)\n",
    "            \n",
    "            if \"rate limit\" in msg.lower() or \"429\" in msg:\n",
    "                time.sleep(delay)\n",
    "                delay = min(delay * 2, 30)\n",
    "                continue\n",
    "            if \"server\" in msg.lower() or \"timeout\" in msg.lower():\n",
    "                time.sleep(delay)\n",
    "                delay = min(delay * 2, 30)\n",
    "                continue\n",
    "            raise\n",
    "    \n",
    "    raise RuntimeError(\"Exhausted retries for this sample.\")\n",
    "\n",
    "run_tag = f\"flare_fpb_{MODEL.replace('-', '_')}\"\n",
    "save_dir = \"/content\"\n",
    "pred_path = f\"{save_dir}/{run_tag}_predictions.csv\"\n",
    "err_path = f\"{save_dir}/{run_tag}_errors.csv\"\n",
    "\n",
    "rows_done = []\n",
    "done_idx = set()\n",
    "if os.path.exists(pred_path):\n",
    "    old = pd.read_csv(pred_path)\n",
    "    if \"row_idx\" in old.columns:\n",
    "        rows_done = old.to_dict(\"records\")\n",
    "        done_idx = set(old[\"row_idx\"].tolist())\n",
    "        print(f\"[resume] loaded {len(done_idx)} completed rows.\")\n",
    "\n",
    "err_rows = []\n",
    "buf = []\n",
    "save_every = 30\n",
    "\n",
    "total = len(ds)\n",
    "print(f\"Starting DeepSeek model evaluation on {total} samples...\")\n",
    "\n",
    "for i in tqdm(range(total)):\n",
    "    if i in done_idx:\n",
    "        continue\n",
    "    x = ds[i]\n",
    "    text = x[\"text\"]\n",
    "    gold = x[\"answer\"]\n",
    "\n",
    "    try:\n",
    "        pred = ask_deepseek(text, LABELS)\n",
    "        raw = json.dumps({\"label\": pred})\n",
    "    except Exception as e:\n",
    "        pred = \"UNKNOWN\"\n",
    "        raw = f\"ERROR: {type(e).__name__}: {e}\"\n",
    "        err_rows.append({\"row_idx\": i, \"id\": x.get(\"id\", i), \"error\": raw, \"text\": text})\n",
    "\n",
    "    buf.append({\n",
    "        \"row_idx\": i,\n",
    "        \"id\": x.get(\"id\", i),\n",
    "        \"text\": text,\n",
    "        \"pred_raw\": raw,\n",
    "        \"pred\": pred,\n",
    "        \"label\": gold\n",
    "    })\n",
    "\n",
    "    if len(buf) % save_every == 0:\n",
    "        out = pd.DataFrame(rows_done + buf).sort_values(\"row_idx\")\n",
    "        out.to_csv(pred_path, index=False)\n",
    "        if err_rows:\n",
    "            pd.DataFrame(err_rows).to_csv(err_path, index=False)\n",
    "        print(f\"[checkpoint] saved {len(out)}/{total} -> {pred_path}\")\n",
    "\n",
    "out = pd.DataFrame(rows_done + buf).sort_values(\"row_idx\")\n",
    "out.to_csv(pred_path, index=False)\n",
    "if err_rows:\n",
    "    pd.DataFrame(err_rows).to_csv(err_path, index=False)\n",
    "print(f\"[done] DeepSeek evaluation completed -> {pred_path}\")\n",
    "if os.path.exists(err_path):\n",
    "    err_count = len(pd.read_csv(err_path)) if os.path.getsize(err_path) > 0 else 0\n",
    "    print(f\"[errors] {err_count} errors logged -> {err_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e78369-4a6e-4724-ad31-810071c56a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc238dc-6590-4f49-8602-ed4974958465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "DeepSeek Model Evaluation Results:\n",
      "Total samples: 970\n",
      "Successful predictions: 970\n",
      "Failed predictions: 0\n",
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS - DeepSeek Chat\n",
      "==================================================\n",
      "Accuracy:  0.7701\n",
      "F1-Macro:  0.7772\n",
      "F1-Micro:  0.7701\n",
      "F1-Weighted: 0.7725\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.95      0.84       116\n",
      "     neutral       0.87      0.73      0.79       577\n",
      "    positive       0.63      0.78      0.70       277\n",
      "\n",
      "    accuracy                           0.77       970\n",
      "   macro avg       0.75      0.82      0.78       970\n",
      "weighted avg       0.79      0.77      0.77       970\n",
      "\n",
      "Confusion Matrix:\n",
      "          negative  neutral  positive\n",
      "negative       110        5         1\n",
      "neutral         33      420       124\n",
      "positive         4       56       217\n",
      "\n",
      "Evaluation results saved -> /content/flare_fpb_deepseek_chat_evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Install scikit-learn first\n",
    "%pip install -q scikit-learn\n",
    "\n",
    "# Then compute Macro-F1 and Accuracy\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# 加载预测结果\n",
    "df = pd.read_csv(pred_path).sort_values(\"row_idx\").drop_duplicates(\"row_idx\", keep=\"last\")\n",
    "ok = df[df[\"pred\"] != \"UNKNOWN\"].copy()\n",
    "\n",
    "print(f\"DeepSeek Model Evaluation Results:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Successful predictions: {len(ok)}\")\n",
    "print(f\"Failed predictions: {len(df) - len(ok)}\")\n",
    "\n",
    "if len(ok) > 0:\n",
    "    # 计算评估指标\n",
    "    f1_macro = f1_score(ok[\"label\"], ok[\"pred\"], labels=LABELS, average=\"macro\", zero_division=0)\n",
    "    f1_micro = f1_score(ok[\"label\"], ok[\"pred\"], labels=LABELS, average=\"micro\", zero_division=0)\n",
    "    f1_weighted = f1_score(ok[\"label\"], ok[\"pred\"], labels=LABELS, average=\"weighted\", zero_division=0)\n",
    "    accuracy = accuracy_score(ok[\"label\"], ok[\"pred\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EVALUATION RESULTS - DeepSeek Chat\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1-Macro:  {f1_macro:.4f}\")\n",
    "    print(f\"F1-Micro:  {f1_micro:.4f}\")\n",
    "    print(f\"F1-Weighted: {f1_weighted:.4f}\")\n",
    "    \n",
    "    # 详细分类报告\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(ok[\"label\"], ok[\"pred\"], labels=LABELS, zero_division=0))\n",
    "    \n",
    "    # 混淆矩阵\n",
    "    print(\"Confusion Matrix:\")\n",
    "    cm = confusion_matrix(ok[\"label\"], ok[\"pred\"], labels=LABELS)\n",
    "    cm_df = pd.DataFrame(cm, index=LABELS, columns=LABELS)\n",
    "    print(cm_df)\n",
    "    \n",
    "    # 保存评估结果\n",
    "    eval_results = {\n",
    "        \"model\": MODEL,\n",
    "        \"dataset\": \"TheFinAI/flare-fpb\",\n",
    "        \"split\": \"test\",\n",
    "        \"total_samples\": len(df),\n",
    "        \"successful_predictions\": len(ok),\n",
    "        \"failed_predictions\": len(df) - len(ok),\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"f1_macro\": float(f1_macro),\n",
    "        \"f1_micro\": float(f1_micro),\n",
    "        \"f1_weighted\": float(f1_weighted),\n",
    "        \"evaluation_time\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()),\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"labels\": LABELS\n",
    "    }\n",
    "    \n",
    "    eval_path = f\"{save_dir}/{run_tag}_evaluation_results.json\"\n",
    "    with open(eval_path, \"w\") as f:\n",
    "        json.dump(eval_results, f, indent=2)\n",
    "    print(f\"\\nEvaluation results saved -> {eval_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No successful predictions to evaluate!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422bed6-96f5-4e62-9f41-7cb8bb54e0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b70d67-0563-4087-8bb9-d0ce8d025c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
