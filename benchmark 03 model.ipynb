{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install -q \"datasets>=2.19.0\" \"huggingface_hub>=0.24\"\n",
    "from huggingface_hub import login\n",
    "login(add_to_git_credential=True)\n",
    "%pip install datasets\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "LABELS = [\"negative\",\"neutral\",\"positive\"]\n",
    "\n",
    "ds_raw = load_dataset(\"TheFinAI/flare-fpb\", split=\"test\")\n",
    "print(\"Loaded flare-fpb test:\", len(ds_raw), \"columns:\", ds_raw.column_names)\n",
    "\n",
    "_alias = {\"pos\":\"positive\",\"neg\":\"negative\",\"neu\":\"neutral\",\n",
    "          \"bullish\":\"positive\",\"bearish\":\"negative\"}\n",
    "\n",
    "def _norm_label(v):\n",
    "    if v is None: return None\n",
    "    if isinstance(v, (int,float)) or (isinstance(v,str) and v.isdigit()):\n",
    "        i = int(v); return LABELS[i] if 0 <= i < len(LABELS) else None\n",
    "    s = str(v).strip().lower(); s = _alias.get(s, s)\n",
    "    return s if s in LABELS else None\n",
    "\n",
    "def _map_row(x):\n",
    "    text = x.get(\"text\") or x.get(\"sentence\") or x.get(\"content\") or x.get(\"input\") or \"\"\n",
    "    lab  = _norm_label(x.get(\"label\", x.get(\"labels\", x.get(\"answer\"))))\n",
    "    return {\"text\": text, \"choices\": LABELS, \"answer\": lab}\n",
    "\n",
    "ds = Dataset.from_list([{**r, **_map_row(r)} for r in ds_raw])\n",
    "bad = [i for i,r in enumerate(ds) if r[\"answer\"] not in LABELS]\n",
    "print(\"Samples with unusable label:\", len(bad))\n",
    "assert len(bad) == 0, \"Found unparseable labels; please check the field mapping.\"\n"
   ],
   "id": "a742be7c673a3212"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%pip install -q \"openai==1.40.2\" \"httpx==0.27.2\" \"httpcore==1.0.5\" \\\n",
    "               \"pandas>=2.2.2\" \"tqdm>=4.66.4\" \"requests>=2.31.0\""
   ],
   "id": "11d9518121bd7414"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os, getpass, json, time, platform\n",
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "try:\n",
    "    LABELS\n",
    "except NameError:\n",
    "    LABELS = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "MODEL    = \"o3\"\n",
    "BASE_URL = \"https://api.openai.com/v1\"\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\") or os.getenv(\"API_KEY\")\n",
    "if not api_key:\n",
    "    api_key = getpass.getpass(\"Paste your OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "run_tag   = f\"flare_fpb_{MODEL.replace('/','_')}\"\n",
    "save_dir  = \"/content\"\n",
    "pred_path = f\"{save_dir}/{run_tag}_predictions.csv\"\n",
    "meta_path = f\"{save_dir}/{run_tag}_metadata.json\"\n",
    "\n",
    "def ver(pkg: str) -> str:\n",
    "    try:\n",
    "        return version(pkg)\n",
    "    except PackageNotFoundError:\n",
    "        return \"not-installed\"\n",
    "\n",
    "meta = {\n",
    "    \"dataset\": \"TheFinAI/flare-fpb\",\n",
    "    \"split\": \"test\",\n",
    "    \"labels\": list(LABELS),\n",
    "    \"model\": MODEL,\n",
    "    \"openai_sdk\": ver(\"openai\"),\n",
    "    \"httpx\": ver(\"httpx\"),\n",
    "    \"httpcore\": ver(\"httpcore\"),\n",
    "    \"datasets_version\": ver(\"datasets\"),\n",
    "    \"pandas\": ver(\"pandas\"),\n",
    "    \"tqdm\": ver(\"tqdm\"),\n",
    "    \"time_utc\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()),\n",
    "    \"python\": platform.python_version(),\n",
    "    \"base_url\": BASE_URL,\n",
    "    \"note\": \"Responses API; strict text-JSON protocol; retries+checkpoint\"\n",
    "}\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Meta saved ->\", meta_path)\n",
    "print(\"MODEL:\", MODEL, \"| BASE_URL:\", BASE_URL)\n",
    "print(\"OPENAI_API_KEY is set:\", bool(os.environ.get(\"OPENAI_API_KEY\")))\n"
   ],
   "id": "b62346d1f43793a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import requests, json, os, re, time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _strip_code_fences(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    if s.startswith(\"```\"):\n",
    "        s = re.sub(r\"^```[a-zA-Z0-9_-]*\\s*\", \"\", s)\n",
    "        s = re.sub(r\"\\s*```$\", \"\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def _extract_output_text(data: dict) -> str | None:\n",
    "    t = data.get(\"output_text\")\n",
    "    if isinstance(t, str) and t.strip():\n",
    "        return t\n",
    "    for o in data.get(\"output\", []):\n",
    "        for p in o.get(\"content\", []):\n",
    "            if p.get(\"type\") == \"output_text\":\n",
    "                tt = p.get(\"text\")\n",
    "                if isinstance(tt, str) and tt.strip():\n",
    "                    return tt\n",
    "    return None\n",
    "\n",
    "def _make_user_text(sentence: str, choices=(\"\",)):\n",
    "    return (\n",
    "        \"Task: classify the sentence into exactly one of these labels: \"\n",
    "        f\"{', '.join(choices)}.\\n\\n\"\n",
    "        f\"Sentence: {sentence}\\n\\n\"\n",
    "        \"Return ONLY a JSON object on a single line, exactly in this form:\\n\"\n",
    "        \"{\\\"label\\\":\\\"negative|neutral|positive\\\"}\\n\"\n",
    "        \"No code fences, no extra text, no explanation.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def safe_post(url, headers, json, max_retries=5, base_delay=2, timeout=300):\n",
    "    delay = base_delay\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            r = requests.post(url, headers=headers, json=json, timeout=timeout)\n",
    "            if r.status_code >= 500:\n",
    "                print(f\"[warn] Server error {r.status_code}, retrying in {delay}s...\")\n",
    "                time.sleep(delay)\n",
    "                delay = min(delay * 2, 60)\n",
    "                continue\n",
    "            return r\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"[warn] Timeout (attempt {attempt+1}), retrying in {delay}s...\")\n",
    "            time.sleep(delay)\n",
    "            delay = min(delay * 2, 60)\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            print(f\"[warn] Connection error: {e}, retrying in {delay}s...\")\n",
    "            time.sleep(delay)\n",
    "            delay = min(delay * 2, 60)\n",
    "    raise RuntimeError(\"Failed after repeated timeouts or connection errors.\")\n",
    "\n",
    "def ask_o3_textjson_once(sentence, choices=(\"negative\",\"neutral\",\"positive\"), max_tok=128):\n",
    "    url = f\"{BASE_URL.rstrip('/')}/responses\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    user_text = _make_user_text(sentence, choices)\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"input\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"input_text\", \"text\": user_text}]\n",
    "        }],\n",
    "        \"max_output_tokens\": int(max_tok),\n",
    "        \"reasoning\": {\"effort\": \"low\"},\n",
    "    }\n",
    "\n",
    "    r = safe_post(url, headers=headers, json=payload)\n",
    "\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        raise RuntimeError(f\"Responses API error {r.status_code}: {r.text[:500]}\")\n",
    "    data = r.json()\n",
    "    if data.get(\"status\") == \"incomplete\":\n",
    "        reason = (data.get(\"incomplete_details\") or {}).get(\"reason\")\n",
    "        raise RuntimeError(f\"incomplete:{reason}\")\n",
    "\n",
    "    txt = _extract_output_text(data)\n",
    "    if not isinstance(txt, str) or not txt.strip():\n",
    "        raise RuntimeError(f\"No output_text in response. Snippet: {json.dumps(data)[:400]}\")\n",
    "\n",
    "    txt = _strip_code_fences(txt)\n",
    "    obj = json.loads(txt)\n",
    "    lab = obj.get(\"label\")\n",
    "    if lab not in choices:\n",
    "        raise RuntimeError(f\"Invalid label {lab!r}; raw json: {obj}\")\n",
    "    return lab\n",
    "\n",
    "def ask_o3_textjson(sentence, choices=(\"negative\",\"neutral\",\"positive\")):\n",
    "    for max_tok in (128, 256, 512):\n",
    "        delay = 1.0\n",
    "        for attempt in range(5):\n",
    "            try:\n",
    "                return ask_o3_textjson_once(sentence, choices, max_tok=max_tok)\n",
    "            except RuntimeError as e:\n",
    "                msg = str(e)\n",
    "\n",
    "                if \"Responses API error 5\" in msg or \"server_error\" in msg:\n",
    "                    time.sleep(delay); delay = min(delay*2, 30); continue\n",
    "                if \"Responses API error 429\" in msg:\n",
    "                    time.sleep(delay); delay = min(delay*2, 60); continue\n",
    "                if \"incomplete:max_output_tokens\" in msg:\n",
    "                    break\n",
    "                raise\n",
    "    raise RuntimeError(\"Exhausted retries and token budgets for this sample.\")\n",
    "\n",
    "run_tag   = f\"flare_fpb_{MODEL.replace('/','_')}\"\n",
    "save_dir  = \"/content\"\n",
    "pred_path = f\"{save_dir}/{run_tag}_predictions.csv\"\n",
    "err_path  = f\"{save_dir}/{run_tag}_errors.csv\"\n",
    "\n",
    "rows_done = []\n",
    "done_idx  = set()\n",
    "if os.path.exists(pred_path):\n",
    "    old = pd.read_csv(pred_path)\n",
    "    if \"row_idx\" in old.columns:\n",
    "        rows_done = old.to_dict(\"records\")\n",
    "        done_idx  = set(old[\"row_idx\"].tolist())\n",
    "        print(f\"[resume] loaded {len(done_idx)} completed rows.\")\n",
    "\n",
    "err_rows = []\n",
    "buf = []\n",
    "save_every = 50\n",
    "\n",
    "total = len(ds)\n",
    "for i in tqdm(range(total)):\n",
    "    if i in done_idx:\n",
    "        continue\n",
    "    x = ds[i]\n",
    "    text = x[\"text\"]\n",
    "    gold = x[\"answer\"]\n",
    "\n",
    "    try:\n",
    "        pred = ask_o3_textjson(text, LABELS)\n",
    "        raw  = json.dumps({\"label\": pred})\n",
    "    except Exception as e:\n",
    "        pred = \"UNKNOWN\"\n",
    "        raw  = f\"ERROR: {type(e).__name__}: {e}\"\n",
    "        err_rows.append({\"row_idx\": i, \"id\": x.get(\"id\", i), \"error\": raw, \"text\": text})\n",
    "\n",
    "    buf.append({\n",
    "        \"row_idx\": i,\n",
    "        \"id\": x.get(\"id\", i),\n",
    "        \"text\": text,\n",
    "        \"pred_raw\": raw,\n",
    "        \"pred\": pred,\n",
    "        \"label\": gold\n",
    "    })\n",
    "\n",
    "    if len(buf) % save_every == 0:\n",
    "        out = pd.DataFrame(rows_done + buf).sort_values(\"row_idx\")\n",
    "        out.to_csv(pred_path, index=False)\n",
    "        if err_rows:\n",
    "            pd.DataFrame(err_rows).to_csv(err_path, index=False)\n",
    "        print(f\"[checkpoint] saved {len(out)}/{total} -> {pred_path}\")\n",
    "\n",
    "out = pd.DataFrame(rows_done + buf).sort_values(\"row_idx\")\n",
    "out.to_csv(pred_path, index=False)\n",
    "if err_rows:\n",
    "    pd.DataFrame(err_rows).to_csv(err_path, index=False)\n",
    "print(f\"[done] saved -> {pred_path}\")\n",
    "if os.path.exists(err_path):\n",
    "    print(f\"[errors] logged -> {err_path}\")\n"
   ],
   "id": "7ccaf0783e146f71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "df = pd.read_csv(pred_path).sort_values(\"row_idx\").drop_duplicates(\"row_idx\", keep=\"last\")\n",
    "ok = df[df[\"pred\"] != \"UNKNOWN\"].copy()\n",
    "\n",
    "try:\n",
    "    LABELS\n",
    "except NameError:\n",
    "    LABELS = [\"negative\",\"neutral\",\"positive\"]\n",
    "\n",
    "f1ma = f1_score(ok[\"label\"], ok[\"pred\"], labels=LABELS, average=\"macro\", zero_division=0)\n",
    "acc  = accuracy_score(ok[\"label\"], ok[\"pred\"])\n",
    "\n",
    "print(f\"F1: {f1ma:.4f}, Accuracy: {acc:.4f}\")"
   ],
   "id": "41d360c5bf4677a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
