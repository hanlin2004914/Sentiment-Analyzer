{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"openai==1.40.2\" \"httpx==0.27.2\" \"httpcore==1.0.5\" datasets pandas scikit-learn tqdm\n",
        "\n"
      ],
      "metadata": {
        "id": "cVl40qZNS0hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "\n",
        "PROVIDER = \"openai\"\n",
        "\n",
        "if PROVIDER == \"openai\":\n",
        "    os.environ[\"API_KEY\"] = getpass.getpass(\"Paste your OpenAI API key: \")\n",
        "    BASE_URL = None\n",
        "    MODEL = \"gpt-4o\"\n",
        "\n",
        "print(\"Provider:\", PROVIDER, \"Model:\", MODEL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO5nsHvpS9jx",
        "outputId": "aa1d5153-0b46-442c-a17a-92e67a2df7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your OpenAI API key: ··········\n",
            "Provider: openai Model: gpt-4o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "ds = load_dataset(\"ChanceFocus/en-fpb\", split=\"test\")\n",
        "len(ds), ds.column_names[:8]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h1AB5NjUNqg",
        "outputId": "fa1f7111-ab83-4ef2-f2be-403acdeb8474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(970, ['id', 'query', 'answer', 'text', 'choices', 'gold'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai, httpx\n",
        "print(\"openai:\", openai.__version__)\n",
        "print(\"httpx:\", httpx.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZScEkKZXvgG",
        "outputId": "17d93bc1-6f5b-4148-8925-d156594a71f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openai: 1.40.2\n",
            "httpx: 0.27.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os, re, time\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "if \"BASE_URL\" not in globals() or BASE_URL is None:\n",
        "    BASE_URL = \"https://api.openai.com/v1\"\n",
        "\n",
        "client = OpenAI(api_key=os.environ[\"API_KEY\"], base_url=BASE_URL)\n",
        "\n",
        "def normalize_to_choice(raw, choices):\n",
        "    if not raw: return None\n",
        "    s = re.split(r\"[\\n\\r]\", raw.strip())[0].strip().strip(\".:;\").lower()\n",
        "    for c in choices:\n",
        "        if s == c.lower(): return c\n",
        "    alias = {\"pos\":\"positive\",\"neg\":\"negative\",\"neu\":\"neutral\",\n",
        "             \"bullish\":\"positive\",\"bearish\":\"negative\"}\n",
        "    s = alias.get(s, s)\n",
        "    for c in choices:\n",
        "        if s == c.lower(): return c\n",
        "    for c in choices:\n",
        "        if c.lower().startswith(s): return c\n",
        "    return None\n",
        "\n",
        "SYSTEM = (\"You are a financial sentiment classifier. \"\n",
        "          \"Choose exactly one label from the options. Output ONLY the label.\")\n",
        "\n",
        "def ask_model(sentence, choices, retries=3, sleep=1):\n",
        "    user = f\"Sentence: {sentence}\\nOptions: {', '.join(choices)}\\nAnswer with ONE of the options only.\"\n",
        "    last_e = None\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=MODEL, temperature=0, max_tokens=8,\n",
        "                messages=[{\"role\":\"system\",\"content\":SYSTEM},\n",
        "                          {\"role\":\"user\",\"content\":user}]\n",
        "            )\n",
        "            return resp.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            last_e = e; time.sleep(sleep)\n",
        "    raise last_e\n"
      ],
      "metadata": {
        "id": "JprRF8hEXvVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex = ds[0]\n",
        "pred_raw = ask_model(ex[\"text\"], list(ex[\"choices\"]))\n",
        "pred = normalize_to_choice(pred_raw, list(ex[\"choices\"]))\n",
        "ex[\"text\"], ex[\"choices\"], pred_raw, pred, ex[\"answer\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb1BtpeOZW0L",
        "outputId": "23b41d60-683e-457f-989f-5d023b3acb68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The new agreement , which expands a long-established cooperation between the companies , involves the transfer of certain engineering and documentation functions from Larox to Etteplan .',\n",
              " ['positive', 'neutral', 'negative'],\n",
              " 'neutral',\n",
              " 'neutral',\n",
              " 'positive')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(ds)\n",
        "rows, y_true, y_pred = [], [], []\n",
        "\n",
        "for i in tqdm(range(N)):\n",
        "    x = ds[i]\n",
        "    choices = list(x[\"choices\"])\n",
        "    gold = x[\"answer\"]\n",
        "    raw = ask_model(x[\"text\"], choices)\n",
        "    pred = normalize_to_choice(raw, choices) or \"UNKNOWN\"\n",
        "    rows.append({\"id\": x.get(\"id\", i), \"text\": x[\"text\"], \"choices\": \"|\".join(choices),\n",
        "                 \"pred_raw\": raw, \"pred\": pred, \"label\": gold})\n",
        "    y_true.append(gold); y_pred.append(pred)\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"/content/fpb_predictions.csv\", index=False)\n",
        "print(\"Saved to /content/fpb_predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuJpHGavZ0dr",
        "outputId": "0c88142d-9ac1-4a59-ef64-91a4c3d2f4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 970/970 [12:42<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/fpb_predictions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ok = df[df[\"pred\"]!=\"UNKNOWN\"]\n",
        "print(\"Used for scoring:\", len(ok), \"/\", len(df))\n",
        "print(\"Accuracy:\", round(accuracy_score(ok[\"label\"], ok[\"pred\"]), 4))\n",
        "print(\"Macro-F1:\", round(f1_score(ok[\"label\"], ok[\"pred\"], average=\"macro\"), 4))\n",
        "print(\"\\nReport:\\n\", classification_report(ok[\"label\"], ok[\"pred\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02pt3PQmdgBH",
        "outputId": "43f415ec-670e-4ac6-90b9-2a3a3036b2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used for scoring: 970 / 970\n",
            "Accuracy: 0.8402\n",
            "Macro-F1: 0.8358\n",
            "\n",
            "Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.97      0.90       116\n",
            "     neutral       0.85      0.89      0.87       577\n",
            "    positive       0.82      0.67      0.74       277\n",
            "\n",
            "    accuracy                           0.84       970\n",
            "   macro avg       0.83      0.85      0.84       970\n",
            "weighted avg       0.84      0.84      0.84       970\n",
            "\n"
          ]
        }
      ]
    }
  ]
}